{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Food Safety Authority Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import OrderedDict\n",
    "from io import StringIO\n",
    "\n",
    "def download_foodsafety_data_and_convert_to_csv(xml_id='FHRS776en-GB.xml', out_fpath='food_safety.csv'):\n",
    "    \"\"\"\n",
    "    Downloads food safety data given the local authority id which can be \n",
    "    found at http://ratings.food.gov.uk/open-data/en-GB \n",
    "    \"\"\"\n",
    "    url = 'http://ratings.food.gov.uk/OpenDataFiles/{}'.format(xml_id)\n",
    "    response = urlopen(url)\n",
    "    content = StringIO(response.read().decode())\n",
    "\n",
    "    def get_info_from_xml():\n",
    "        etree = ET.parse(content)\n",
    "        root = etree.getroot()\n",
    "        for enstab in root.iter('EstablishmentDetail'):\n",
    "            d = OrderedDict()\n",
    "            for item in enstab:\n",
    "                if item.tag == 'Geocode':\n",
    "                    for ll_info in item:\n",
    "                        d[ll_info.tag] = float(ll_info.text)\n",
    "                else:\n",
    "                    d[item.tag] = item.text\n",
    "            yield d\n",
    "\n",
    "    df = pd.DataFrame(list(get_info_from_xml()))\n",
    "    df.to_csv(out_fpath, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_foodsafety_data_and_convert_to_csv(xml_id='FHRS776en-GB.xml', out_fpath='food_safety_Glasgow.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Yelp Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a Yelp API KEY follow [these info](https://www.yelp.com/developers/documentation/v3/authentication). \n",
    "Then create a file called api_key.py with *YELP_API_KEY=<your yelp api key\\>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import YELP_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "import json\n",
    "\n",
    "class Client():\n",
    "    endpoint = 'https://api.yelp.com/v3/businesses/search?'\n",
    "    valid_seach_keys = ['term','location','latitude','longitude','radius','categories','locale','limit','offset','sort_by','price','open_now','open_at','attributes']\n",
    "\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "    \n",
    "    def request(self, endpoint):\n",
    "        #print(f'GET requesting: {endpoint}')\n",
    "        headers = {\"Authorization\":f\"Bearer {self.api_key}\"}\n",
    "        r = requests.get(endpoint, headers=headers)\n",
    "        return r\n",
    "        \n",
    "    def search_businesses(self, **kwargs):\n",
    "        verbose = kwargs.pop('verbose', False)\n",
    "        for k in kwargs.keys():\n",
    "            assert k in self.valid_seach_keys\n",
    "        search_values = [f'{k}={quote(str(v))}' for k,v in kwargs.items()]\n",
    "        url = self.endpoint + '&'.join(search_values)\n",
    "        if verbose: print('Sending request:', url)\n",
    "        r = self.request(url)\n",
    "        return r\n",
    "    \n",
    "def save_to_json(obj, fpath='yelp.json'):\n",
    "    with open(fpath, 'w') as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "def load_from_json(fpath='yelp.json'):\n",
    "    with open(fpath, 'r') as f:\n",
    "        content = json.load(f)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downlaoding Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(api_key=YELP_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude, longitude = 55.863937, -4.270185  # M8 bridge\n",
    "radius = 5000\n",
    "categories = 'restaurants'\n",
    "limit = 50  # max=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added: 50, curr len=50\n",
      "added: 50, curr len=100\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "last_search_results = limit\n",
    "MAX_SIZE = 1000\n",
    "all_businesses = []\n",
    "\n",
    "while last_search_results >= limit and offset < MAX_SIZE:\n",
    "    r = c.search_businesses(\n",
    "        latitude=latitude, \n",
    "        longitude=longitude, \n",
    "        radius=radius, \n",
    "        categories=categories, \n",
    "        offset=offset, \n",
    "        limit=limit\n",
    "    )\n",
    "    if 'error' in r.json():\n",
    "        print(r.json())\n",
    "        break\n",
    "    \n",
    "    found_businesses = r.json()['businesses']\n",
    "    last_search_results = len(found_businesses)\n",
    "    offset += last_search_results\n",
    "    \n",
    "    all_businesses.extend(found_businesses)\n",
    "    print(f'added: {last_search_results}, curr len={len(all_businesses)}')\n",
    "\n",
    "save_to_json(obj=all_businesses, fpath='yelp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert json to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_item_to_record(b):\n",
    "    EXCLUDE = ['display_address']\n",
    "    record = {}\n",
    "    for k,v in b.items():\n",
    "        if k in EXCLUDE: continue\n",
    "        if isinstance(v, (int, float, bool, str)):\n",
    "            record[k] = v\n",
    "        elif isinstance(v, dict):\n",
    "            sub_record = convert_item_to_record(v)\n",
    "            record.update(sub_record)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_businesses = load_from_json(fpath='yelp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [convert_item_to_record(b) for b in all_businesses]\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "ordered_col = [\n",
    "    'name', 'rating', 'review_count',  'price',\n",
    "    'latitude', 'longitude', 'zip_code', \n",
    "    'id', 'alias',\n",
    "    'address1', 'address2', 'address3',  'city', 'state', 'country',\n",
    "    'display_phone', 'image_url', 'phone', 'url'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ordered_col].to_csv('yelp.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fsa = pd.read_csv('food_safety_Glasgow.csv')\n",
    "df_yelp = pd.read_csv('yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = df_yelp[['name', 'latitude', 'longitude', 'zip_code', 'id', 'address1']].copy()\n",
    "df_fsa = df_fsa[['FHRSID', 'BusinessName', 'AddressLine2', 'PostCode', 'Longitude', 'Latitude']].copy()\n",
    "\n",
    "df_yelp = df_yelp[pd.notnull(df_yelp.latitude) & pd.notnull(df_yelp['name'])]\n",
    "df_fsa = df_fsa[pd.notnull(df_fsa.Latitude) & pd.notnull(df_fsa['BusinessName'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_score(lat, lon, lat_ref, lon_ref):\n",
    "    lat_diff = lat - lat_ref\n",
    "    lon_diff = lon - lon_ref\n",
    "    pseudo_dist = np.hypot(lat_diff, lon_diff)\n",
    "    return np.exp(-pseudo_dist*100)\n",
    "\n",
    "@np.vectorize\n",
    "def get_str_compare_score(addr, addr_ref):\n",
    "    score = SequenceMatcher(None, addr, addr_ref).ratio()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_SCORE_THREASHOLD = 0.8\n",
    "NAME_SCORE_THREASHOLD = 0.5\n",
    "\n",
    "MATCHES = {}\n",
    "def find_matches(df):\n",
    "    for i_counter, (idx, item) in enumerate(df.iterrows()):\n",
    "        search_df = df_fsa.copy()\n",
    "\n",
    "        # filter by distance\n",
    "        # ==================\n",
    "        score_dist = get_distance_score(\n",
    "            lat=search_df.Latitude, lon=search_df.Longitude, \n",
    "            lat_ref=item.latitude, lon_ref=item.longitude\n",
    "        )\n",
    "        search_df = search_df[score_dist >= DIST_SCORE_THREASHOLD]\n",
    "        if search_df.empty: continue\n",
    "\n",
    "        # score by name\n",
    "        # =============\n",
    "        search_df['scores'] = get_str_compare_score(addr=search_df.BusinessName, addr_ref=item['name'])\n",
    "        search_df = search_df[search_df['scores'] >= NAME_SCORE_THREASHOLD]\n",
    "        MATCHES[item['id']] = search_df[['FHRSID','scores']].set_index('FHRSID')['scores'].to_dict()\n",
    "\n",
    "        # get best match\n",
    "        # ==============\n",
    "        if search_df.empty:\n",
    "            idx_best_match = score_best_match = best_matching_FHRSID = np.nan\n",
    "        else:\n",
    "            idx_best_match = search_df['scores'].idxmax()\n",
    "            score_best_match = search_df.loc[idx_best_match].scores\n",
    "            best_matching_FHRSID = search_df.loc[idx_best_match].FHRSID\n",
    "        print(f'\\rMatched {i_counter}/{df.shape[0]}: {best_matching_FHRSID}, score: {score_best_match}', end='')\n",
    "    \n",
    "    return MATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 99/100: 79746, score: 1.0"
     ]
    }
   ],
   "source": [
    "matches_dict = find_matches(df=df_yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating match matrix\n",
    "match_matrix = pd.DataFrame(matches_dict)\n",
    "match_matrix.index.name = 'FHRSID'\n",
    "match_matrix.columns.name = 'yelp_id'\n",
    "match_matrix.head()\n",
    "\n",
    "# combining reciprocal maximums scoring matches only\n",
    "col_max = match_matrix.idxmax(axis=1)\n",
    "row_max = match_matrix.idxmax(axis=0)\n",
    "col_max.name = 'yelp_id'\n",
    "row_max.name = 'FHRSID'\n",
    "d1 = col_max.reset_index()\n",
    "d2 = row_max.reset_index()\n",
    "df_matches = pd.merge(d1, d2, on=['FHRSID', 'yelp_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.to_csv('matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding FHRSID to Yelp dataset via inner join\n",
    "df_yelp_full = pd.read_csv('yelp.csv')\n",
    "df_agumented = pd.merge(left=df_yelp_full, right=df_matches, left_on='id', right_on='yelp_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agumented[['name', 'rating', 'review_count', 'price', 'latitude', 'longitude', 'zip_code', 'id', 'address1', 'FHRSID']]\\\n",
    "    .to_csv('yelp_matched.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
